{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-14T04:09:17.505762Z",
     "iopub.status.busy": "2023-12-14T04:09:17.505359Z",
     "iopub.status.idle": "2023-12-14T04:09:17.513834Z",
     "shell.execute_reply": "2023-12-14T04:09:17.512093Z",
     "shell.execute_reply.started": "2023-12-14T04:09:17.505736Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import roc_auc_score,roc_curve,auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import import_ipynb\n",
    "from function_for_eda import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Bước 1</b>: Merging tất cả các bảng qua SK_ID_CURR feature <br>\n",
    "<b>Bước 2</b>: Tạo một số feature mới liên quan đến AMT_INCOME ở bảng tổng(bảng đã merge tất cả các bảng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:09:17.516225Z",
     "iopub.status.busy": "2023-12-14T04:09:17.515875Z",
     "iopub.status.idle": "2023-12-14T04:09:17.529645Z",
     "shell.execute_reply": "2023-12-14T04:09:17.528702Z",
     "shell.execute_reply.started": "2023-12-14T04:09:17.516195Z"
    }
   },
   "outputs": [],
   "source": [
    "def merge_all_tables(application_train, application_test, bureau_aggregated, previous_aggregated, \n",
    "                    installments_aggregated, pos_aggregated, cc_aggregated):\n",
    "    '''\n",
    "    Function to merge all the tables together with the application_train and application_test tables\n",
    "    on SK_ID_CURR.\n",
    "    \n",
    "    Inputs:\n",
    "        All the previously pre-processed Tables.\n",
    "        \n",
    "    Returns:\n",
    "        Single merged tables, one for training data and one for test data\n",
    "    '''\n",
    "\n",
    "    #merging application_train and application_test with Aggregated bureau table\n",
    "    app_train_merged = application_train.merge(bureau_aggregated, on = 'SK_ID_CURR', how = 'left')\n",
    "    app_test_merged = application_test.merge(bureau_aggregated, on = 'SK_ID_CURR', how = 'left')\n",
    "    #merging with aggregated previous_applications\n",
    "    app_train_merged = app_train_merged.merge(previous_aggregated, on = 'SK_ID_CURR', how = 'left')\n",
    "    app_test_merged = app_test_merged.merge(previous_aggregated, on = 'SK_ID_CURR', how = 'left')\n",
    "    #merging with aggregated installments tables\n",
    "    app_train_merged = app_train_merged.merge(installments_aggregated, on = 'SK_ID_CURR', how = 'left')\n",
    "    app_test_merged = app_test_merged.merge(installments_aggregated, on = 'SK_ID_CURR', how = 'left')\n",
    "    #merging with aggregated POS_Cash balance table\n",
    "    app_train_merged = app_train_merged.merge(pos_aggregated, on = 'SK_ID_CURR', how = 'left')\n",
    "    app_test_merged = app_test_merged.merge(pos_aggregated, on = 'SK_ID_CURR', how = 'left')\n",
    "    #merging with aggregated credit card table\n",
    "    app_train_merged = app_train_merged.merge(cc_aggregated, on = 'SK_ID_CURR', how = 'left')\n",
    "    app_test_merged = app_test_merged.merge(cc_aggregated, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "    return app_train_merged, app_test_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:09:17.531696Z",
     "iopub.status.busy": "2023-12-14T04:09:17.531137Z",
     "iopub.status.idle": "2023-12-14T04:10:31.846339Z",
     "shell.execute_reply": "2023-12-14T04:10:31.845380Z",
     "shell.execute_reply.started": "2023-12-14T04:09:17.531662Z"
    }
   },
   "outputs": [],
   "source": [
    "application_train = pd.read_csv('/kaggle/input/final-data/application_train_final.csv')\n",
    "application_test = pd.read_csv('/kaggle/input/final-data/application_test_final.csv')\n",
    "bureau_aggregated = pd.read_csv('/kaggle/input/final-data/bureau_balance_final.csv')\n",
    "previous_aggregated = pd.read_csv('/kaggle/input/pre-app/previous_application_final.csv')\n",
    "installments_aggregated = pd.read_csv('/kaggle/input/final-data/installments_payments_final.csv')\n",
    "pos_aggregated  = pd.read_csv('/kaggle/input/final-data/pos_cash_final.csv')\n",
    "cc_aggregated = pd.read_csv('/kaggle/input/final-data/credit_cat_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:10:31.848205Z",
     "iopub.status.busy": "2023-12-14T04:10:31.847722Z",
     "iopub.status.idle": "2023-12-14T04:10:37.056754Z",
     "shell.execute_reply": "2023-12-14T04:10:37.055753Z",
     "shell.execute_reply.started": "2023-12-14T04:10:31.848178Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data, test_data = merge_all_tables(application_train, application_test, \n",
    "                                         bureau_aggregated, previous_aggregated, \n",
    "                                         installments_aggregated, pos_aggregated, \n",
    "                                         cc_aggregated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEW FEATURE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Đây đều là những features liên quan đến tỉ lệ của các khoản 'AMT_ANNUITY', 'AMT_RECEIVABLE_PRINCIPAL', 'AMT_GOODS',  'AMT_PAYMENT' so với INCOME của người đi vay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:10:37.060031Z",
     "iopub.status.busy": "2023-12-14T04:10:37.059767Z",
     "iopub.status.idle": "2023-12-14T04:10:37.073534Z",
     "shell.execute_reply": "2023-12-14T04:10:37.072182Z",
     "shell.execute_reply.started": "2023-12-14T04:10:37.060010Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_new_features(data):\n",
    "    '''\n",
    "    Function to create few more features after the merging of features, by using the\n",
    "    interactions between various tables.\n",
    "    \n",
    "    Inputs:\n",
    "        data: DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    \n",
    "    #previous applications columns\n",
    "    prev_annuity_columns = [ele for ele in previous_aggregated.columns if 'AMT_ANNUITY' in ele]\n",
    "    for col in prev_annuity_columns:\n",
    "        data['PREV_' + col + '_INCOME_RATIO'] = data[col] / (data['AMT_INCOME_TOTAL'] + 0.00001)\n",
    "    prev_goods_columns = [ele for ele in previous_aggregated.columns if 'AMT_GOODS' in ele]\n",
    "    for col in prev_goods_columns:\n",
    "        data['PREV_' + col + '_INCOME_RATIO'] = data[col] / (data['AMT_INCOME_TOTAL'] + 0.00001)\n",
    "  \n",
    "    #credit_card_balance columns\n",
    "    cc_amt_principal_cols = [ele for ele in cc_aggregated.columns if 'AMT_RECEIVABLE_PRINCIPAL' in ele]\n",
    "    for col in cc_amt_principal_cols:\n",
    "        data['CC_' + col + '_INCOME_RATIO'] = data[col] / (data['AMT_INCOME_TOTAL'] + 0.00001)\n",
    "    cc_amt_recivable_cols = [ele for ele in cc_aggregated.columns if 'AMT_RECIVABLE' in ele]\n",
    "    for col in cc_amt_recivable_cols:\n",
    "        data['CC_' + col + '_INCOME_RATIO'] = data[col] / (data['AMT_INCOME_TOTAL'] + 0.00001)\n",
    "    cc_amt_total_receivable_cols = [ele for ele in cc_aggregated.columns if 'TOTAL_RECEIVABLE' in ele]\n",
    "    for col in cc_amt_total_receivable_cols:\n",
    "        data['CC_' + col + '_INCOME_RATIO'] = data[col] / (data['AMT_INCOME_TOTAL'] + 0.00001)\n",
    "    \n",
    "    #installments_payments columns\n",
    "    installments_payment_cols = [ele for ele in installments_aggregated.columns if 'AMT_PAYMENT' in ele and 'RATIO' not in ele and 'DIFF' not in ele]\n",
    "    for col in installments_payment_cols:\n",
    "        data['INSTALLMENTS_' + col + '_INCOME_RATIO'] = data[col] / (data['AMT_INCOME_TOTAL'] + 0.00001)\n",
    "    #https://www.kaggle.com/c/home-credit-default-risk/discussion/64821\n",
    "    installments_max_installment = ['AMT_INSTALMENT_MEAN_MAX', 'AMT_INSTALMENT_SUM_MAX']\n",
    "    for col in installments_max_installment:\n",
    "        data['INSTALLMENTS_ANNUITY_' + col + '_RATIO'] = data['AMT_ANNUITY'] / (data[col] + 0.00001)\n",
    "\n",
    "    bureau_overdue_cols = [ele for ele in bureau_aggregated.columns if 'AMT_CREDIT' in ele and 'OVERDUE' in ele]\n",
    "    for col in bureau_overdue_cols:\n",
    "        data['BUREAU_' + col + '_INCOME_RATIO'] = data[col] / (data['AMT_INCOME_TOTAL'] + 0.00001)\n",
    "    bureau_amt_annuity_cols = [ele for ele in bureau_aggregated.columns if 'AMT_ANNUITY' in ele and 'CREDIT'  not in ele]\n",
    "    for col in bureau_amt_annuity_cols:\n",
    "        data['BUREAU_' + col + '_INCOME_RATIO'] = data[col] / (data['AMT_INCOME_TOTAL'] + 0.00001)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:10:37.075771Z",
     "iopub.status.busy": "2023-12-14T04:10:37.075331Z",
     "iopub.status.idle": "2023-12-14T04:10:37.206715Z",
     "shell.execute_reply": "2023-12-14T04:10:37.205010Z",
     "shell.execute_reply.started": "2023-12-14T04:10:37.075743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Pre-processing, aggregation, merging and Feature Engineering,\n",
      "Final Shape of Training Data = (246009, 1649)\n",
      "Final Shape of Test Data = (61502, 1648)\n"
     ]
    }
   ],
   "source": [
    "create_new_features(train_data)\n",
    "create_new_features(test_data)\n",
    "\n",
    "print(\"After Pre-processing, aggregation, merging and Feature Engineering,\")\n",
    "print(f\"Final Shape of Training Data = {train_data.shape}\")\n",
    "print(f\"Final Shape of Test Data = {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:10:37.238538Z",
     "iopub.status.busy": "2023-12-14T04:10:37.237456Z",
     "iopub.status.idle": "2023-12-14T04:12:56.523862Z",
     "shell.execute_reply": "2023-12-14T04:12:56.521861Z",
     "shell.execute_reply.started": "2023-12-14T04:10:37.238503Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "test_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "train_data = remove_missing_col(train_data)\n",
    "test_data = remove_missing_col(test_data)\n",
    "\n",
    "train_data = fill_nan(train_data)\n",
    "test_data = fill_nan(test_data)\n",
    "\n",
    "train_data = replace_outlier(train_data)\n",
    "test_data = replace_outlier(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:12:56.526865Z",
     "iopub.status.busy": "2023-12-14T04:12:56.526356Z",
     "iopub.status.idle": "2023-12-14T04:13:01.563428Z",
     "shell.execute_reply": "2023-12-14T04:13:01.561770Z",
     "shell.execute_reply.started": "2023-12-14T04:12:56.526822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 columns with just 1 unique value\n",
      "Removing these from dataset\n"
     ]
    }
   ],
   "source": [
    "empty_columns = []\n",
    "for col in train_data.columns:\n",
    "    if len(train_data[col].unique()) <=1:\n",
    "        empty_columns.append(col)\n",
    "    \n",
    "print(f\"There are {len(empty_columns)} columns with just 1 unique value\")\n",
    "print(\"Removing these from dataset\")\n",
    "train_data = train_data.drop(empty_columns, axis = 1)\n",
    "test_data = test_data.drop(empty_columns, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:13:01.565420Z",
     "iopub.status.busy": "2023-12-14T04:13:01.564954Z",
     "iopub.status.idle": "2023-12-14T04:13:03.149751Z",
     "shell.execute_reply": "2023-12-14T04:13:03.148637Z",
     "shell.execute_reply.started": "2023-12-14T04:13:01.565382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features shape:  (246009, 1204)\n",
      "Testing Features shape:  (61502, 1203)\n"
     ]
    }
   ],
   "source": [
    "# Align the training and testing data, keep only columns present in both dataframes\n",
    "train_data = train_data.drop('SK_ID_CURR', axis =1)\n",
    "train_labels = train_data.pop('TARGET')\n",
    "train_data, test_data = train_data.align(test_data, join = 'inner', axis = 1)\n",
    "\n",
    "# Add the target back in\n",
    "train_data['TARGET'] = train_labels\n",
    "\n",
    "print('Training Features shape: ', train_data.shape)\n",
    "print('Testing Features shape: ', test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:13:03.151970Z",
     "iopub.status.busy": "2023-12-14T04:13:03.151078Z",
     "iopub.status.idle": "2023-12-14T04:13:03.157784Z",
     "shell.execute_reply": "2023-12-14T04:13:03.155983Z",
     "shell.execute_reply.started": "2023-12-14T04:13:03.151934Z"
    }
   },
   "outputs": [],
   "source": [
    "#train_data.to_csv('data_train_final.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:13:03.160679Z",
     "iopub.status.busy": "2023-12-14T04:13:03.159679Z",
     "iopub.status.idle": "2023-12-14T04:13:03.171637Z",
     "shell.execute_reply": "2023-12-14T04:13:03.169238Z",
     "shell.execute_reply.started": "2023-12-14T04:13:03.160641Z"
    }
   },
   "outputs": [],
   "source": [
    "#test_data.to_csv('data_test_final.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on data train tổng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:13:03.176108Z",
     "iopub.status.busy": "2023-12-14T04:13:03.175716Z",
     "iopub.status.idle": "2023-12-14T04:13:21.625855Z",
     "shell.execute_reply": "2023-12-14T04:13:21.623776Z",
     "shell.execute_reply.started": "2023-12-14T04:13:03.176077Z"
    }
   },
   "outputs": [],
   "source": [
    "train,test1 = train_test_split(train_data,test_size=.25,random_state = 123)\n",
    "\n",
    "#separating dependent and independent variables\n",
    "train_x1 = train[[i for i in train.columns if i not in ['SK_ID_CURR'] + [ 'TARGET']]]\n",
    "scaler = StandardScaler()\n",
    "train_x1 = scaler.fit_transform(train_x1)\n",
    "train_y1 = np.array(train[[\"TARGET\"]])\n",
    "\n",
    "test_x1 = test1[[i for i in test1.columns if i not in ['SK_ID_CURR'] + [ 'TARGET']]]\n",
    "test_x1 = scaler.fit_transform(test_x1)\n",
    "test_y1 = np.array(test1[[\"TARGET\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:13:21.628268Z",
     "iopub.status.busy": "2023-12-14T04:13:21.627761Z",
     "iopub.status.idle": "2023-12-14T04:14:00.081286Z",
     "shell.execute_reply": "2023-12-14T04:14:00.080371Z",
     "shell.execute_reply.started": "2023-12-14T04:13:21.628228Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Make the model with the specified regularization parameter\n",
    "log_reg = LogisticRegression(solver = 'newton-cholesky', penalty = 'l2', C= 0.001, max_iter = 500)\n",
    "#log_reg = LogisticRegression(solver = 'saga', max_iter = 97, penalty = 'l2', C= 0.00160957244252) # thay bộ best param vào đây\n",
    "\n",
    "\n",
    "log_reg.fit(train_x1, train_y1)\n",
    "log_reg_pred = log_reg.predict_proba(test_x1)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T04:14:00.083426Z",
     "iopub.status.busy": "2023-12-14T04:14:00.082754Z",
     "iopub.status.idle": "2023-12-14T04:14:00.111952Z",
     "shell.execute_reply": "2023-12-14T04:14:00.111219Z",
     "shell.execute_reply.started": "2023-12-14T04:14:00.083392Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC Score: 0.7806501776667601\n",
      "Gini Score: 0.5613003553335203\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "auc_roc = roc_auc_score(test_y1,log_reg_pred)\n",
    "gini = 2 * auc_roc - 1\n",
    "print(f\"AUC-ROC Score: {auc_roc}\")\n",
    "print(f\"Gini Score: {gini}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6994796,
     "sourceId": 63890,
     "sourceType": "competition"
    },
    {
     "datasetId": 4151819,
     "sourceId": 7182678,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4152893,
     "sourceId": 7184118,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4153030,
     "sourceId": 7184307,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30615,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
